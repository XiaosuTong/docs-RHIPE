### Read and Divide by Time ###

Same as before, we can create the subsets of dataset divided by time variable. But here one of
potential problem that we may face is that what if some of the subsets are very large? This is
a very general problem if we are dealing with a large and complex dataset. In fact, `Rhipe` is 
able to write any size of subset to HDFS, but only can read less than 256 Mb subset from HDFS.
In other words, we are able to create any size of subset in a mapreduce job, but we will get 
issue when we are trying to read and apply analysis method on oversize subset.

In this example, we are assuming that each subset of data by time is oversize, so we are going
to create multiple subset for same time string.

#### Map ####

```{r eval=FALSE, tidy=FALSE}
map6 <- expression({
  lapply(seq_along(map.keys), function(r) {
    line = strsplit(map.values[[r]], ",")[[1]]
    key <- line[[4]]
    value <- as.data.frame(rbind(line[-4]), stringsAsFactors = FALSE)
    rhcollect(key, value)
  })
})
```

#### Reduce ####

```{r eval=FALSE, tidy=FALSE}
reduce6 <- expression(
  pre = {
  },
  reduce = {
    tmp <- data.frame()
    tmp <- rbind(tmp, do.call(rbind, reduce.values))
    names(tmp) <- c(
      "fips", "county", "state", 
      "sold", "list", "selling"
    )
    tmp$list <- as.numeric(tmp$list)
    tmp$selling <- as.numeric(tmp$selling)
    rhcollect(reduce.key, tmp)
  },
  post = {
  }
)
```

#### Execution Function ####

```{r eval=FALSE, tidy=FALSE}
mr6 <- rhwatch(
  map      = map6,
  reduce   = reduce6,
  input    = rhfmt("/ln/tmp/housing/housing.txt", type = "text"),
  output   = rhfmt("/ln/tmp/housing/bytime", type = "sequence"),
  mapred   = list(
    mapred.reduce.tasks = 10,
    rhipe_reduce_buff_size = 500
  ),
  readback = FALSE
)
```

### Compute Total Sold ###

We then would like to calculate the total sold units for every month over all states.

#### Without Combiner ####

```{r eval=FALSE, tidy=FALSE}
map7 <- expression({
  lapply(seq_along(map.keys), function(r) {
    key <- map.keys[[r]]
    value <- sum(as.numeric(map.values[[r]]$sold), na.rm = TRUE)
    rhcollect(key, value)
  })
})
reduce7 <- expression(
  pre = {
    count <- 0
  },
  reduce = {
    count <- count + sum(unlist(reduce.values), na.rm = TRUE)
  },
  post = {
    rhcollect(reduce.key, count)
  }
)
```

In the map expression, we calculated the sum of the sold units for each key
```{r eval=FALSE, tidy=FALSE}
mr7 <- rhwatch(
  map       = map7,
  reduce    = reduce7,
  input     = rhfmt("/ln/tmp/housing/bytime", type = "sequence"),
  output    = rhfmt("/ln/tmp/housing/soldbytime", type = "sequence"),
  mapred    = list(
    mapred.reduce.tasks = 10
  ),
  jobname   = "total sold unit for each month",
  mon.sec   = 10,
  combiner  = FALSE,
  readback  = FALSE
)
```

The default for combiner is `FALSE`, which is what we have used before.

#### Combiner as an Optimization ####

Between the map phase and reduce phase of a MapReduce job, Hadoop sends all the intermediate values
for a given key to the reducer. The intermediate values for a given key are located on several compute 
nodes and need to be shuffled (sent across the network) to the node assigned the processing of that
intermediate key. This involves a lot of network transfer.

Some operations do not need access to all of the data (intermediate values), i.e they can compute on 
subsets and order does not matter, i.e associative and commutative operations. For example, the minimum, 
or the sum, of some numbers. In these cases, a combiner can be useful.

The idea of the combiner is that the reduce is first run locally on mapper outputs before they are sent 
for the final reduce. When the combiner is enabled, the reduction occurs just after the map phase on a 
subset of intermediate values for a given intermediate keys. The output of this is then sent to the 
reducer. This greatly reduces network transfer and accelerates the job speed, especially if the output 
from a map contains a lot of data.

#### Enabling Combiner in RHIPE ####

Combiner can be enabled in `Rhipe` by specifying `combiner = TRUE` when calling function `rhwatch()`.

To be able to use a combiner, your reduce expression needs to pass the same data type as it receives,
i.e the two arguments in the function rhcollect() in your map expression need to be of the same type as 
those in the function rhcollect() in your reduce expression. For example, if you pass a string as the key
and a numeric vector as the value in the map expression, you need to pass a string as key and a numeric 
vector as the value in the reduce expression as well.

We will demonstrate the usage of combiners through the following examples.

```{r eval=FALSE, tidy=FALSE}
mr8 <- rhwatch(
  map       = map7,
  reduce    = reduce7,
  input     = rhfmt("/ln/tmp/housing/bytime", type = "sequence"),
  output    = rhfmt("/ln/tmp/housing/soldbytime.combiner", type = "sequence"),
  mapred    = list(
    mapred.reduce.tasks = 10
  ),
  jobname   = "total sold unit for each month with combiner",
  mon.sec   = 10,
  combiner  = TRUE,
  readback  = FALSE
)
```

```{r eval=FALSE, tidy=FALSE}
rst.comb <- rhread("/ln/tmp/housing/soldbytime.combiner")
rst <- rhread("/ln/tmp/housing/soldbytime")
identical(rst, rst.comb)
```
```
[1] TRUE
```
```{r eval=FALSE, tidy=FALSE}
df <- data.frame(  
  time  = sapply(rst, "[[", 1),
  total = sapply(rst, "[[", 2)
)
df <- df[order(df$time, decreasing = FALSE), ]  
df.comb <- data.frame(  
  time  = sapply(rst.comb, "[[", 1),
  total = sapply(rst.comb, "[[", 2)
)
df.comb <- df.comb[order(df.comb$time, decreasing = FALSE), ]
head(df.comb)
head(df)
```
```
         time  total
45 2008-10-01 272879
50 2008-11-01 201648
59 2008-12-01 229829
51 2009-01-01 180674
60 2009-02-01 187276
1  2009-03-01 219149
```
